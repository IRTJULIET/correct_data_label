{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "dataset = pandas.read_csv(url, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 5)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 7\n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "model_selection.train_test_split(X, \n",
    "                                 Y, \n",
    "                                 test_size=validation_size, \n",
    "                                 random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.966667 (0.040825)\n",
      "LDA: 0.975000 (0.038188)\n",
      "KNN: 0.983333 (0.033333)\n",
      "CART: 0.975000 (0.038188)\n",
      "NB: 0.975000 (0.053359)\n",
      "SVM: 0.991667 (0.025000)\n"
     ]
    }
   ],
   "source": [
    "# evaluate each model in turn\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "[[ 7  0  0]\n",
      " [ 0 11  1]\n",
      " [ 0  2  9]]\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00         7\n",
      "Iris-versicolor       0.85      0.92      0.88        12\n",
      " Iris-virginica       0.90      0.82      0.86        11\n",
      "\n",
      "    avg / total       0.90      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, Y_train)\n",
    "predictions = knn.predict(X_validation)\n",
    "print(accuracy_score(Y_validation, predictions))\n",
    "print(confusion_matrix(Y_validation, predictions))\n",
    "print(classification_report(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong Label Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "    names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "    dataset = pandas.read_csv(url, names=names)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(dataset['class'].unique())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = shuffle(dataset)\n",
    "dataset = dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(dataset['class'].unique())\n",
    "def make_wrong(dataset, num_of_wrongs):\n",
    "    change_indexes = random.sample(range(0,len(dataset)+1), num_of_wrongs)\n",
    "    print('change_indexes :\\n', change_indexes)\n",
    "    trues = []\n",
    "    wrongs = []\n",
    "    for i in change_indexes:\n",
    "        true_label = dataset.at[i , 'class']\n",
    "        trues.append(true_label)\n",
    "        wrong_label = random.choice([i for i in labels if i != true_label])\n",
    "        wrongs.append(wrong_label)\n",
    "        dataset.at[i , 'class'] = wrong_label\n",
    "    print('trues :\\n', trues)\n",
    "    print('wrongs :\\n', wrongs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_models():\n",
    "    models = {}\n",
    "    models['LR'] = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "    models['LDA'] = LinearDiscriminantAnalysis()\n",
    "    models['KNN'] = KNeighborsClassifier()\n",
    "    models['CART'] = DecisionTreeClassifier()\n",
    "    models['NB'] = GaussianNB()\n",
    "    models['SVM'] = SVC(gamma='auto')\n",
    "    return models\n",
    "m = form_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = 4\n",
    "array = dataset.values\n",
    "X = array[:,0:num_of_features]\n",
    "Y = array[:,num_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataset = shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width            class\n",
       "29            4.7          3.2           1.6          0.2      Iris-setosa\n",
       "125           7.2          3.2           6.0          1.8   Iris-virginica\n",
       "55            5.7          2.8           4.5          1.3  Iris-versicolor\n",
       "66            5.6          3.0           4.5          1.5  Iris-versicolor\n",
       "131           7.9          3.8           6.4          2.0   Iris-virginica\n",
       "31            5.4          3.4           1.5          0.4      Iris-setosa\n",
       "63            6.1          2.9           4.7          1.4  Iris-versicolor\n",
       "87            6.3          2.3           4.4          1.3  Iris-versicolor\n",
       "10            5.4          3.7           1.5          0.2      Iris-setosa\n",
       "37            4.9          3.1           1.5          0.1      Iris-setosa"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = shuffled_dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width\n",
       "29            4.7          3.2           1.6          0.2\n",
       "125           7.2          3.2           6.0          1.8\n",
       "55            5.7          2.8           4.5          1.3\n",
       "66            5.6          3.0           4.5          1.5\n",
       "131           7.9          3.8           6.4          2.0\n",
       "31            5.4          3.4           1.5          0.4\n",
       "63            6.1          2.9           4.7          1.4\n",
       "87            6.3          2.3           4.4          1.3\n",
       "10            5.4          3.7           1.5          0.2\n",
       "37            4.9          3.1           1.5          0.1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = t[t.columns[0:4]]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 29\n",
      "1 125\n",
      "2 55\n",
      "3 66\n",
      "4 131\n",
      "5 31\n",
      "6 63\n",
      "7 87\n",
      "8 10\n",
      "9 37\n"
     ]
    }
   ],
   "source": [
    "for i, index in enumerate(list(X_test.index)):\n",
    "    print(i,index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {1: ['a']})"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = defaultdict(list)\n",
    "d[1].append('a')\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[1].append('a')\n",
    "d[1].append('b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pandas.read_csv('/Users/muratyalcin/Downloads/train.csv')\n",
    "t.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas, random\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from collections import defaultdict, Counter\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "class correct_labels:\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dataset,\n",
    "                 label_column_name:str, \n",
    "                 num_of_wrongs, \n",
    "                 repeats, \n",
    "                 split_rate = 4, # 3/4 train, 1/4 predict\n",
    "                 iris = None,\n",
    "                 mnist = None):\n",
    "        self.dataset = dataset\n",
    "        self.label_column_name = label_column_name\n",
    "        self.split_rate = split_rate \n",
    "        self.num_of_wrongs = num_of_wrongs\n",
    "        self.repeats = repeats\n",
    "        self.models = self.form_models()\n",
    "        #if iris:\n",
    "        #    assert mnist is None\n",
    "        #    self.dataset = self.load_iris_dataset()\n",
    "        #if mnist:\n",
    "        #    self.dataset = self.load_mnist_dataset()\n",
    "        self.num_of_features = self.dataset.shape[1]-1\n",
    "        self.labels = list(self.dataset[label_column_name].unique())\n",
    "        self.num_of_labels = len(self.labels)\n",
    "        \n",
    "    \n",
    "    def load_iris_dataset(self):\n",
    "        url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/iris.csv\"\n",
    "        names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "        dataset = pandas.read_csv(url, names=names)\n",
    "        return dataset\n",
    "    \n",
    "    def load_mnist_dataset(self):\n",
    "        t = pandas.read_csv('/Users/muratyalcin/Downloads/train.csv')\n",
    "        cols = list(t.columns)\n",
    "        cols = cols[1:] + [cols[0]]\n",
    "        dataset = t[cols]\n",
    "        return dataset\n",
    "    \n",
    "    def shuffle_dataset(self, dataset):\n",
    "        shuffled_dataset = shuffle(dataset)\n",
    "        #shuffled_dataset = shuffled_dataset.reset_index(drop=True)\n",
    "        return shuffled_dataset\n",
    "        \n",
    "    def make_wrong(self, dataset):\n",
    "        change_indexes = random.sample(range(0,len(dataset)+1),\n",
    "                                       self.num_of_wrongs)\n",
    "        trues = []\n",
    "        wrongs = []\n",
    "        wrong_dataset = dataset.copy()\n",
    "        for i in change_indexes:\n",
    "            true_label = self.dataset.at[i , self.label_column_name]\n",
    "            trues.append(true_label)\n",
    "            wrong_label = random.choice([i for i in self.labels if i != true_label])\n",
    "            wrongs.append(wrong_label)\n",
    "            wrong_dataset.at[i , self.label_column_name] = wrong_label\n",
    "        return wrong_dataset, trues, wrongs, change_indexes\n",
    "    \n",
    "    def dataset_train_test_split(self, dataset):\n",
    "        split_point = int(len(dataset)/self.split_rate)\n",
    "        train_data = dataset[split_point:]\n",
    "        test_data = dataset[:split_point]\n",
    "        return train_data, test_data, split_point\n",
    "    \n",
    "    def df_to_vector(self, df):\n",
    "        return df.values\n",
    "        \n",
    "    def x_y_split_vector(self, vector):\n",
    "        X = vector[:,0:self.num_of_features]\n",
    "        y = vector[:,self.num_of_features]\n",
    "        return X, y \n",
    "        \n",
    "    def form_models(self):\n",
    "        models = {}\n",
    "        #models['LR'] = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "        #models['LDA'] = LinearDiscriminantAnalysis()\n",
    "        #models['KNN'] = KNeighborsClassifier()\n",
    "#         models['CART'] = DecisionTreeClassifier()\n",
    "#         models['RF'] = RandomForestClassifier()\n",
    "        #models['NB'] = GaussianNB()\n",
    "        #models['SVM'] = SVC(gamma='auto')\n",
    "        #models['baseline'] = self.baseline_model()\n",
    "        models['CNN'] = self.create_cnn_model()\n",
    "        return models\n",
    "    \n",
    "    def create_cnn_model(self):\n",
    "        # Set the CNN model \n",
    "        # my CNN architechture is In -> [[Conv2D->relu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Dropout -> Out\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                         activation ='relu', input_shape = (28,28,1)))\n",
    "        model.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                         activation ='relu'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = \"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10, activation = \"softmax\"))\n",
    "        \n",
    "        # Define the optimizer\n",
    "        optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "        # Compile the model\n",
    "        model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        return model\n",
    "        \n",
    "    def baseline_model(self):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.num_of_features, input_dim=self.num_of_features, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(self.num_of_labels, kernel_initializer='normal', activation='softmax'))\n",
    "        # Compile model\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "       \n",
    "\n",
    "    def fit_cnn(self, model, X_train, Y_train, X_val, Y_val):\n",
    "        epochs = 1 # Turn epochs to 30 to get 0.9967 accuracy\n",
    "        batch_size = 64\n",
    "\n",
    "        # without data augmentation\n",
    "        model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, \n",
    "        validation_data = (X_val, Y_val), verbose = 2)\n",
    "\n",
    "        return model     \n",
    "    \n",
    "    def fit_(self, model, X_train, y_train):\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def predict_(self, model,  X_test):\n",
    "        predictions = model.predict(X_test)\n",
    "        return predictions\n",
    "        \n",
    "    def multi_model_predict(self, X_train, y_train, X_test):\n",
    "        preds = []\n",
    "        for model in list(self.models.values()):\n",
    "            model = self.fit_(model, X_train, y_train)\n",
    "            predictions = self.predict_(X_test)\n",
    "            preds.append(predictions)\n",
    "        return preds\n",
    "    \n",
    "    def multi_model_predict_cnn(self, X_train, Y_train, X_val, Y_val, X_test):\n",
    "        preds = []\n",
    "        for model in list(self.models.values()):\n",
    "            model = self.fit_cnn(model, X_train, Y_train, X_val, Y_val)\n",
    "            predictions = self.predict_(model, X_test)\n",
    "            print('predictions before : \\n', predictions)\n",
    "            # Convert predictions classes to one hot vectors \n",
    "            predictions = np.argmax(predictions,axis = 1) \n",
    "            print('predictions after : \\n', predictions)\n",
    "            preds.append(predictions)\n",
    "        return preds\n",
    "    \n",
    "    \n",
    "    def handle_tracker(self, tracker, wrong_dataset):\n",
    "        wrong_data_labels = list(wrong_dataset[self.label_column_name])\n",
    "        assert len(list(self.dataset[self.label_column_name])) == \\\n",
    "        len(list(wrong_dataset[self.label_column_name]))\n",
    "        item_preds = defaultdict()\n",
    "        model_guess = []\n",
    "        for i in range(len(self.dataset)):\n",
    "            if tracker[i]:\n",
    "                item_preds[i] = max(Counter(tracker[i]), key=Counter(tracker[i]).get) \n",
    "                model_guess.append(max(Counter(tracker[i]), key=Counter(tracker[i]).get))\n",
    "            else:\n",
    "                item_preds[i] = wrong_data_labels[i]\n",
    "                model_guess.append(wrong_data_labels[i])\n",
    "        return item_preds, model_guess\n",
    "   \n",
    "    def compare(self, model_guess):\n",
    "        actuals = list(self.dataset[self.label_column_name])\n",
    "        predicted = model_guess \n",
    "        corrects = [i for i, j in enumerate(zip(actuals, model_guess)) if j[0] == j[1]]\n",
    "        wrongs = [i for i, j in enumerate(zip(actuals, model_guess)) if j[0] != j[1]]\n",
    "        return corrects, wrongs\n",
    " \n",
    "    def evaluate(self, corrects, change_indexes, wrongs):\n",
    "        return {\n",
    "            'data length' : len(self.dataset),\n",
    "            'split rate' : self.split_rate,\n",
    "            'repeats' : self.repeats,\n",
    "            'total wrongs start' : self.num_of_wrongs,\n",
    "            'number of corrects' : len(corrects),\n",
    "            'number of wrongs' : len(wrongs),\n",
    "            'number of wrong indexes'  : len(change_indexes),\n",
    "            'number of corrected' : len(set(change_indexes) & set(corrects)),\n",
    "            'number of missed' : len(set(change_indexes) & set(wrongs)), \n",
    "            'number of wronged' : len((set(change_indexes) | set(wrongs)) - set(change_indexes))   \n",
    "        }\n",
    "        \n",
    "    def correct_wrong_labels(self):\n",
    "        tracker = defaultdict(list)\n",
    "        wrong_dataset, trues, wrongs, change_indexes = self.make_wrong(self.dataset)\n",
    "        for i in range(self.repeats):\n",
    "            dataset = self.shuffle_dataset(wrong_dataset)\n",
    "            train_data, test_data, split_point = self.dataset_train_test_split(wrong_dataset)\n",
    "            train_data_ = self.df_to_vector(train_data)\n",
    "            test_data_ = self.df_to_vector(test_data)\n",
    "            X_train, y_train = self.x_y_split_vector(train_data_)\n",
    "            X_test, y_test = self.x_y_split_vector(test_data_) \n",
    "            \n",
    "            preds = self.multi_model_predict(X_train, y_train, X_test)\n",
    "            num_models = len(self.models)\n",
    "            assert len(preds[0]) == split_point\n",
    "            y_indexes = list(test_data.index)\n",
    "            for x in range(num_models):\n",
    "                for i, index in enumerate(y_indexes):\n",
    "                    tracker[index].append(preds[x][i])\n",
    "        item_preds, model_guess = self.handle_tracker(tracker, wrong_dataset)\n",
    "        corrects, wrongs = self.compare(model_guess)\n",
    "        result = self.evaluate(corrects, change_indexes, wrongs)\n",
    "        print('result : ', result) \n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def correct_wrong_labels_cnn(self):\n",
    "        tracker = defaultdict(list)\n",
    "        wrong_dataset, trues, wrongs, change_indexes = self.make_wrong(self.dataset)\n",
    "        for i in range(self.repeats):\n",
    "            print(f'processing {i}/{self.repeats}')\n",
    "            dataset = self.shuffle_dataset(wrong_dataset)\n",
    "            train_data, test_data, split_point = self.dataset_train_test_split(wrong_dataset)\n",
    "            # Drop 'label' column\n",
    "            X_train = train_data.drop(labels = [\"label\"],axis = 1) \n",
    "            Y_train = train_data[\"label\"]\n",
    "\n",
    "            X_test = test_data.drop(labels = [\"label\"],axis = 1) \n",
    "            Y_test = test_data[\"label\"]\n",
    "            # Normalize the data\n",
    "            X_train = X_train / 255.0\n",
    "            X_test = X_test / 255.0\n",
    "\n",
    "            # Reshape image in 3 dimensions (height = 28px, width = 28px , canal = 1)\n",
    "            X_train = X_train.values.reshape(-1,28,28,1)\n",
    "            X_test = X_test.values.reshape(-1,28,28,1)\n",
    "            \n",
    "            # Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
    "            Y_train = to_categorical(Y_train, num_classes = 10)\n",
    "            Y_test = to_categorical(Y_test, num_classes = 10)\n",
    "            \n",
    "            # Split the train and the validation set for the fitting\n",
    "            X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)\n",
    "\n",
    "            \n",
    "#             # Set a learning rate annealer\n",
    "#             learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "#                                             patience=3, \n",
    "#                                             verbose=1, \n",
    "#                                             factor=0.5, \n",
    "#                                             min_lr=0.00001)\n",
    "\n",
    "#             datagen = ImageDataGenerator(\n",
    "#                     featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "#                     samplewise_center=False,  # set each sample mean to 0\n",
    "#                     featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "#                     samplewise_std_normalization=False,  # divide each input by its std\n",
    "#                     zca_whitening=False,  # apply ZCA whitening\n",
    "#                     rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#                     zoom_range = 0.1, # Randomly zoom image \n",
    "#                     width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "#                     height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "#                     horizontal_flip=False,  # randomly flip images\n",
    "#                     vertical_flip=False)  # randomly flip images\n",
    "\n",
    "#             datagen.fit(X_train)\n",
    "            \n",
    "#             # Fit the model\n",
    "#             history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=batch_size),\n",
    "#                               epochs = epochs, validation_data = (X_val,Y_val),\n",
    "#                               verbose = 2, steps_per_epoch=X_train.shape[0] // batch_size\n",
    "#                               , callbacks=[learning_rate_reduction])\n",
    "            print('multi model prediction in progress...')\n",
    "            preds = self.multi_model_predict_cnn(X_train, Y_train, X_val, Y_val, X_test)\n",
    "            print('multi model prediction completed successfully...')\n",
    "            num_models = len(self.models)\n",
    "            assert len(preds[0]) == split_point\n",
    "            y_indexes = list(test_data.index)\n",
    "            for x in range(num_models):\n",
    "                for i, index in enumerate(y_indexes):\n",
    "                    tracker[index].append(preds[x][i])\n",
    "        item_preds, model_guess = self.handle_tracker(tracker, wrong_dataset)\n",
    "        corrects, wrongs = self.compare(model_guess)\n",
    "        result = self.evaluate(corrects, change_indexes, wrongs)\n",
    "        print('result : ', result) \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_correct(num_of_wrongs, repeats, split_rate):\n",
    "    def load_mnist_dataset():\n",
    "        t = pandas.read_csv('/Users/muratyalcin/Downloads/train.csv')\n",
    "        cols = list(t.columns)\n",
    "        cols = cols[1:] + [cols[0]]\n",
    "        dataset = t[cols]\n",
    "        return dataset\n",
    "    num_of_wrongs = num_of_wrongs\n",
    "    repeats = repeats\n",
    "    split_rate = split_rate\n",
    "    results = []\n",
    "    print('loading dataset...')\n",
    "    dataset = load_mnist_dataset()\n",
    "    print('experiment started...')\n",
    "    for i in num_of_wrongs:\n",
    "        for j in repeats:\n",
    "            for k in split_rate:\n",
    "                cl = correct_labels(dataset = dataset,\n",
    "                                    label_column_name = 'label', \n",
    "                                    num_of_wrongs = i, \n",
    "                                    repeats = j, \n",
    "                                    split_rate = k,\n",
    "                                   mnist = True)\n",
    "                print('\\ncombination : \\n', (i, j, k) , '\\n')\n",
    "                result = cl.correct_wrong_labels_cnn()\n",
    "                results.append(result)\n",
    "    res = pandas.DataFrame(results)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset...\n",
      "experiment started...\n",
      "\n",
      "combination : \n",
      " (100, 1, 100) \n",
      "\n",
      "processing 0/1\n",
      "multi model prediction in progress...\n",
      "Train on 37422 samples, validate on 4158 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "num_of_wrongs = [100]\n",
    "repeats = [1]\n",
    "split_rate = [100]\n",
    "start_correct(num_of_wrongs, repeats, split_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data length</th>\n",
       "      <th>number of corrected</th>\n",
       "      <th>number of corrects</th>\n",
       "      <th>number of missed</th>\n",
       "      <th>number of wrong indexes</th>\n",
       "      <th>number of wronged</th>\n",
       "      <th>number of wrongs</th>\n",
       "      <th>repeats</th>\n",
       "      <th>split rate</th>\n",
       "      <th>total wrongs start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42000</td>\n",
       "      <td>3</td>\n",
       "      <td>40805</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1193</td>\n",
       "      <td>1195</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42000</td>\n",
       "      <td>3</td>\n",
       "      <td>40858</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>1130</td>\n",
       "      <td>1142</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data length  number of corrected  number of corrects  number of missed  \\\n",
       "0        42000                    3               40805                 2   \n",
       "1        42000                    3               40858                12   \n",
       "\n",
       "   number of wrong indexes  number of wronged  number of wrongs  repeats  \\\n",
       "0                        5               1193              1195       10   \n",
       "1                       15               1130              1142       10   \n",
       "\n",
       "   split rate  total wrongs start  \n",
       "0           3                   5  \n",
       "1           3                  15  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = correct_labels('class', num_of_wrongs = 5, repeats = 10000, split_rate = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result :  {'data length': 150, 'number of corrects': 148, 'number of wrongs': 2, 'number of wrong indexes': 5, 'number of corrected': 3, 'number of missed': 2, 'number of wronged': 0}\n"
     ]
    }
   ],
   "source": [
    "cl.correct_wrong_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load():\n",
    "    import pandas\n",
    "    t = pandas.read_csv('/Users/muratyalcin/Downloads/train.csv')\n",
    "    cols = list(t.columns)\n",
    "    cols = cols[1:] + [cols[0]]\n",
    "    dataset = t[cols]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...    pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...           0         0         0         0         0         0   \n",
       "1       0  ...           0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  label  \n",
       "0         0         0         0      1  \n",
       "1         0         0         0      0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(t.columns)\n",
    "cols = cols[1:] + [cols[0]]\n",
    "df = t[cols]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.datasets import mnist\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
